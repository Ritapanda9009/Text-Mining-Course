{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "colab": {
      "name": "Lab 05 - Part of Speech Tagging, Starting with Pandas.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/organisciak/Text-Mining-Course/blob/independentstudy/labs/Lab%2005%20-%20Part%20of%20Speech%20Tagging%2C%20Starting%20with%20Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FbahTrdTMUy",
        "colab_type": "text"
      },
      "source": [
        "# Lab 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfdaG1G3TMU9",
        "colab_type": "text"
      },
      "source": [
        "## Part of Speech Tagging\n",
        "\n",
        "And tuples!\n",
        "\n",
        "Here is how you tag parts-of-speech with NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st4CrkEBTMVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "6682440e-71fd-4ca5-8b6c-8516cb4bda72"
      },
      "source": [
        "import nltk\n",
        "nltk.download(['punkt', 'averaged_perceptron_tagger'], quiet=True)\n",
        "text = \"And now for something completely different\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('And', 'CC'),\n",
              " ('now', 'RB'),\n",
              " ('for', 'IN'),\n",
              " ('something', 'NN'),\n",
              " ('completely', 'RB'),\n",
              " ('different', 'JJ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHUUKweUTMWG",
        "colab_type": "text"
      },
      "source": [
        "The output of `pos_tag` is a list of objects called 'tuples'. You can access a tuple by index or you can easily expand it into multiple variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-d6X-ySTMWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1f232cb-e02e-431a-9e59-99e96f6bb1ac"
      },
      "source": [
        "test_tuple = ('England', 'PRP')\n",
        "test_tuple"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('England', 'PRP')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2r6QGH6TMWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88372449-f8b7-4b94-94f5-dbdf7ef4abea"
      },
      "source": [
        "test_tuple[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'England'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MebTRDAXTMWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bdae684-5ad5-41b5-9b16-d595d479490b"
      },
      "source": [
        "word, pos = test_tuple\n",
        "word"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'England'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoq4yVHeTMWi",
        "colab_type": "text"
      },
      "source": [
        "Since you can expand tuples easily, you can name the parts of a tuple in a list comprehension. Note in the following example that we follow a `for x, y in list_of_tuples` pattern instead of `for x in list_of_tuples` as we've encountered before: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLl5-xAVTMWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff13c9d9-2c96-4a4f-d68b-620a87442378"
      },
      "source": [
        "[tag for word, tag in tagged]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CC', 'RB', 'IN', 'NN', 'RB', 'JJ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOizdfGaTMWn",
        "colab_type": "text"
      },
      "source": [
        "The `for x,y in list_of_tuples` approach also works for in for loops.\n",
        "\n",
        "Tuples don't need to have only two values in Python, but that's the most common. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuOEuNEwTMWn",
        "colab_type": "text"
      },
      "source": [
        "**Q1**: How do you get a list of all the singular proper nouns tagged by NLTK in Frankenstein? Share just the code.\n",
        "\n",
        "Part of Speech tag definitions are at [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html). To double check, the output of your code should start with `['St.', 'Petersburgh', 'Dec.', 'TO', 'Mrs.']`. For Python beginners, note that comparing strings is done with `==`, as in `string == string2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H009ZiVpTMWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting started\n",
        "from smart_open import open\n",
        "with open(\"https://github.com/organisciak/Text-Mining-Course/blob/independentstudy/data/frankenstein.txt\") as f:\n",
        "    frank_string = f.read()\n",
        "frank_tokens = nltk.word_tokenize(frank_string)\n",
        "\n",
        "# ... what's next?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3KEomA6TMW0",
        "colab_type": "text"
      },
      "source": [
        "# Getting into Pandas and the HTRC Extracted Features\n",
        "\n",
        "For the rest of the lab, follow along with [Text Mining in Python with the HTRC Feature Reader](http://programminghistorian.org/lessons/text-mining-with-extracted-features) up to and including \"Selecting Subsets of a DataFrame by a Condition\" (i.e. stop when you see 'Slicing DataFrames'). This tutorial will introduce you to two things:\n",
        " 1. The HTRC Extracted Features Dataset, which we discussed last week.\n",
        " 2. A library called Pandas, an important part of our toolkit moving forward.\n",
        "\n",
        "You'll be able to skim many of the early parts of the tutorial, since you've already learned those skills. Don't overlook \"Installing the HTRC Feature Reader\", though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqm_bUR5TMW1",
        "colab_type": "text"
      },
      "source": [
        "*Questions*\n",
        "\n",
        "I've posted an HTRC Extracted Features file: [mdp.49015002392919.json.bz2]( https://github.com/organisciak/Text-Mining-Course/blob/master/data/mdp.49015002392919.json.bz2). Use the Feature Reader library to answer the following questions about that file:\n",
        "\n",
        "**Q2**: What is the title of the book?\n",
        "\n",
        " 1. 'The adventures of Tom Sawyer, by Mark Twain (Samuel L. Clemens)...'\n",
        " 2. 'Frankenstein : or, The modern Prometheus.'\n",
        " 3. 'June / by Edith Barnard Delano ; with illustrations.'\n",
        " 4. 'Anne of Green Gables / L.M. Montgomery.'\n",
        " 5. None of the above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFhJEMEmTMW1",
        "colab_type": "text"
      },
      "source": [
        "**Q3**: What is the URL to read this book online at the HathiTrust Digital Library?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRUqJML1TMW2",
        "colab_type": "text"
      },
      "source": [
        "**Q4**: Which of these charts is the plot of tokens/page across the entire book?\n",
        "\n",
        "1. ![](https://github.com/organisciak/Text-Mining-Course/blob/independentstudy/images/lab5-plot1.png?raw=1)\n",
        "2. ![](https://github.com/organisciak/Text-Mining-Course/blob/independentstudy/images/lab5-plot2.png?raw=1)\n",
        "3. ![](https://github.com/organisciak/Text-Mining-Course/blob/independentstudy/images/lab5-plot3.png?raw=1)\n",
        "5. None of the above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "M9FdM0LuTMW3",
        "colab_type": "text"
      },
      "source": [
        "**Q5**: How do you get the word frequencies for the header throughout the book? (Not changing any of the other default arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2-x5BcFTMW3",
        "colab_type": "text"
      },
      "source": [
        "**Q6**: How do you get the count of each word in the body of the text for the entire book, not worrying about pages or parts of speech? Share your code. *Hint: the length of the correct output (i.e. `len(object_from_your_answer)`) is `9267`.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewDwxZ58TMW4",
        "colab_type": "text"
      },
      "source": [
        "**Q7**: In the output from Q6, which of the following parts are indexes or columns?\n",
        "\n",
        "*section*: index, column, or doesn't exist\n",
        "\n",
        "*word*:    index, column, or doesn't exist\n",
        "\n",
        "*token*:   index, column, or doesn't exist\n",
        "\n",
        "*count*:   index, column, or doesn't exist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88rIlmPyTMW6",
        "colab_type": "text"
      },
      "source": [
        "**Q8**: Setting the output to Q6 to a variable called `tl`, what is the line of code to sort values in descending order? To figure out the answer, you can try searching online about sorting in Pandas, or try auto-complete and documentation lookup in Jupyter to see what `tl` can do and how.\n",
        "\n",
        "If it is ordered correctly, the top words will be '`,`' (4934 occurrences), '`.`' (3866), and '`the`' (3320)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtoJTw8jTMXA",
        "colab_type": "text"
      },
      "source": [
        "**Q9**: Here is a list of words that show up 64 times in `tl`: [can, face, seemed, where]. What other words with a count of 64 are missing?\n",
        "\n",
        " - than\n",
        " - hand\n",
        " - want\n",
        " - heart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vggu0afkTMXB",
        "colab_type": "text"
      },
      "source": [
        "What if we wanted to work with our text in a DataFrame? Here's how you would convert the list of part-of-speech tagged tuples into a DataFrame, where I called my initial list `frank_tagged`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_bxi2jlTMXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "frank_df = pd.DataFrame(frank_tagged, columns=['word', 'pos'])\n",
        "frank_df.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXhPinebTMXF",
        "colab_type": "text"
      },
      "source": [
        "Pandas is - by convention, not rule - imported with the name `pd`. Note that gave the columns names.\n",
        "\n",
        "**Q10**: What code would you use on `frank_df` to get the singular proper nouns? It should give you 1371 rows."
      ]
    }
  ]
}